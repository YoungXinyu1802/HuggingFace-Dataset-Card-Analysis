## Dataset Summary

A dataset for benchmarking keyphrase extraction and generation techniques from english scientific papers. For more details about the dataset please refer the original paper - [https://dl.acm.org/doi/abs/10.1145/313238.313437](https://dl.acm.org/doi/abs/10.1145/313238.313437)

Original source of the data - []()


## Dataset Structure


### Data Fields

- **id**: unique identifier of the document.
- **document**: Whitespace separated list of words in the document.
- **doc_bio_tags**: BIO tags for each word in the document. B stands for the beginning of a keyphrase and I stands for inside the keyphrase. O stands for outside the keyphrase and represents the word that isn't a part of the keyphrase at all.
- **extractive_keyphrases**: List of all the present keyphrases.
- **abstractive_keyphrase**: List of all the absent keyphrases.


### Data Splits

|Split| #datapoints  |
|--|--|
| Train | 130 |
| Test | 500 |

Train

- Percentage of keyphrases that are named entities: 69.49% (named entities detected using scispacy - en-core-sci-lg model)
- Percentage of keyphrases that are noun phrases: 81.26% (noun phrases detected using spacy en-core-web-lg after removing determiners)

Test

- Percentage of keyphrases that are named entities: 70.79% (named entities detected using scispacy - en-core-sci-lg model)
- Percentage of keyphrases that are noun phrases: 82.74% (noun phrases detected using spacy en-core-web-lg after removing determiners)


## Usage

### Full Dataset

```python
from datasets import load_dataset

# get entire dataset
dataset = load_dataset("midas/cstr", "raw")

# sample from the train split
print("Sample from train dataset split")
test_sample = dataset["train"][0]
print("Fields in the sample: ", [key for key in test_sample.keys()])
print("Tokenized Document: ", test_sample["document"])
print("Document BIO Tags: ", test_sample["doc_bio_tags"])
print("Extractive/present Keyphrases: ", test_sample["extractive_keyphrases"])
print("Abstractive/absent Keyphrases: ", test_sample["abstractive_keyphrases"])
print("\n-----------\n")

# sample from the test split
print("Sample from test dataset split")
test_sample = dataset["test"][0]
print("Fields in the sample: ", [key for key in test_sample.keys()])
print("Tokenized Document: ", test_sample["document"])
print("Document BIO Tags: ", test_sample["doc_bio_tags"])
print("Extractive/present Keyphrases: ", test_sample["extractive_keyphrases"])
print("Abstractive/absent Keyphrases: ", test_sample["abstractive_keyphrases"])
print("\n-----------\n")
```
**Output**

```bash
Sample from training data split
Fields in the sample:  ['id', 'document', 'doc_bio_tags', 'extractive_keyphrases', 'abstractive_keyphrases', 'other_metadata']
Tokenized Document:  ['Reasoning', 'with', 'Non-Atomic', 'Memories', 'Manhoi', 'Choy', '?', 'and', 'Ambuj', 'K.', 'Singh', '?', 'Department', 'of', 'Computer', 'Science', 'University', 'of', 'California', 'at', 'Santa', 'Barbara', 'Santa', 'Barbara', ',', 'CA', '93106', 'August', '3', ',', '1993', 'Abstract', 'A', 'method', 'for', 'reasoning', 'with', 'non-atomic', 'memory', 'is', 'developed', '.', 'A', 'program', 'using', 'non-atomic', 'memory', 'is', 'transformed', 'into', 'an', 'equivalent', 'one', 'that', 'uses', 'atomic', 'memory', '.', 'A', 'number', 'of', 'non-atomic', 'memories', 'including', 'pipelined', 'RAM', ',', 'causal', 'memory', ',', 'and', 'hybrid', 'consistency', 'are', 'examined', '.', 'The', 'approach', 'is', 'illustrated', 'with', 'some', 'examples', '.', '1', 'Introduction', 'The', 'traditional', 'abstraction', 'of', 'shared', 'memory', 'which', 'supported', 'atomic', 'reads', 'and', 'writes', 'has', 'come', 'under', 'increasing', 'scrutiny', '.', 'Hardware', 'architects', 'seem', 'to', 'agree', 'that', 'atomic', 'memory', 'leads', 'to', 'a', 'large', 'latency', 'that', 'is', 'unacceptable', 'for', 'efficient', 'programming', '.', 'Based', 'on', 'this', 'observation', ',', 'non-atomic', 'abstractions', 'of', 'shared', 'memory', 'have', 'been', 'proposed', 'in', 'the', 'literature', '.', 'These', 'definitions', 'are', 'usually', 'motivated', 'by', 'hardware', 'and', 'their', 'semantics', 'and', 'usefulness', 'from', 'the', 'point', 'of', 'view', 'of', 'a', 'user', 'are', 'far', 'from', 'clear', '.', 'Coupled', 'with', 'the', 'problems', 'of', 'concurrency', 'and', 'non-determinism', ',', 'these', 'definitions', 'have', 'the', 'potential', 'of', 'making', 'the', 'programming', 'of', 'concurrent', 'systems', 'very', 'difficult', '.', 'This', 'paper', 'examines', 'some', 'existing', 'definitions', 'of', 'non-atomic', 'memories', 'and', 'provides', 'a', 'mechanism', 'for', 'reasoning', 'about', 'them', '.', 'Instead', 'of', 'designing', 'a', 'new', 'proof', 'system', 'for', 'each', 'kind', 'of', 'non-atomic', 'memory', ',', 'our', 'approach', 'is', 'to', 'define', 'rules', 'for', 'transforming', 'a', 'program', 'that', 'uses', 'non-atomic', 'memory', 'into', 'an', 'equivalent', 'program', 'that', 'uses', 'atomic', 'memory', '.', 'The', 'transformed', 'program', 'can', 'then', 'be', 'proved', 'using', 'any', 'of', 'the', 'existing', 'proof', 'systems', 'such', 'as', 'Temporal', 'logic', '-LSB-', '15', '-RSB-', 'and', 'Unity', '-LSB-', '6', '-RSB-', '.', 'Besides', 'providing', 'a', 'technique', 'for', 'reasoning', 'about', 'non-atomic', 'memory', ',', 'the', 'approach', 'also', 'provides', 'a', 'clear', 'uniform', 'semantics', 'for', 'the', 'non-atomic', 'memories', '.', 'Traditional', 'approaches', 'toward', 'defining', 'non-atomic', 'memories', 'are', 'based', 'on', 'histories', '.', 'Systemwide', 'execution', 'histories', 'are', 'considered', 'and', 'those', 'that', 'satisfy', 'the', 'specification', 'are', 'isolated', 'by', 'considering', 'interleavings', 'of', 'events', '.', 'It', 'may', 'be', 'difficult', 'for', 'users', 'to', 'understand', 'the', 'semantics', 'of', 'non-atomic', 'operations', 'in', 'such', 'an', 'approach', '.', 'In', 'contrast', ',', 'the', 'technique', 'proposed', 'here', 'is', 'based', 'on', 'the', 'idea', 'of', 'transforming', 'each', 'non-atomic', 'operation', 'as', 'a', 'set', 'of', 'atomic', 'operations', '.', 'The', 'motivation', 'is', 'to', 'show', 'that', 'understanding', 'non-atomic', 'memories', 'is', ',', 'in', 'principle', ',', '?', 'Work', 'supported', 'in', 'part', 'by', 'NSF', 'grant', 'CCR-9008628', '.', 'no', 'harder', 'that', 'understanding', 'atomic', 'memories', '.', 'This', 'approach', 'of', 'transforming', 'a', 'program', 'that', 'uses', 'non-atomic', 'variables', 'into', 'one', 'that', 'uses', 'atomic', 'variables', 'was', 'used', 'earlier', 'by', 'Anderson', 'and', 'Gouda', '-LSB-', '3', '-RSB-', 'to', 'prove', 'the', 'correctness', 'of', 'programs', 'that', 'use', 'safe', 'and', 'regular', 'variables', '-LSB-', '11', '-RSB-', '.', 'The', 'specific', 'abstractions', 'of', 'non-atomic', 'memory', 'that', 'we', 'examine', 'include', 'pipelined', 'RAM', '-LSB-', '12', '-RSB-', ',', 'causal', 'memory', '-LSB-', '2', '-RSB-', ',', 'TSO', 'and', 'PSO', 'memory', 'models', 'of', 'Sparc', '-LSB-', '9', '-RSB-', ',', 'and', 'hybrid', 'consistency', '-LSB-', '5', '-RSB-', '.', 'In', 'each', 'of', 'these', 'cases', ',', 'suitable', 'auxiliary', 'variables', 'are', 'defined', 'in', 'the', 'process', 'of', 'transformation', '.', 'These', 'auxiliary', 'variables', 'may', 'be', 'viewed', 'as', 'an', 'abstract', 'implementation', 'of', 'the', 'corresponding', 'kind', 'of', 'memory', '.', 'The', 'rest', 'of', 'the', 'paper', 'is', 'organized', 'as', 'follows', '.', 'Sections', '2', 'through', '6', 'examine', 'the', 'different', 'kinds', 'of', 'memory', '.', 'In', 'each', 'case', ',', 'rules', 'for', 'transforming', 'each', 'non-atomic', 'read', 'and', 'write', 'are', 'included', '.', 'In', 'some', 'cases', ',', 'the', 'transformations', 'are', 'also', 'illustrated', 'with', 'small', 'examples', '.', 'Section', '7', 'includes', 'a', 'brief', 'discussion', '.', '2', 'Pipelined', 'RAM', 'In', 'this', 'kind', 'of', 'non-atomic', 'memory', 'introduced', 'by', 'Lipton', 'and', 'Sandberg', '-LSB-', '12', '-RSB-', ',', 'every', 'process', 'has', 'its', 'own', 'copy', 'of', 'the', 'shared', 'memory', '.', 'A', 'read', 'operation', 'is', 'performed', 'by', 'reading', 'this', 'local', 'copy', 'and', 'a', 'write', 'operation', 'is', 'performed', 'by', 'updating', 'the', 'local', 'copy', 'and', 'sending', 'the', 'update', 'to', 'all', 'other', 'processes', 'on', 'FIFO', 'channels', '.', 'These', 'updates', 'are', 'then', 'executed', 'asynchronously', 'at', 'the', 'remote', 'processes', '.', 'In', 'order', 'to', 'model', 'this', 'memory', ',', 'we', 'introduce', 'the', 'following', 'auxiliary', 'variables', 'for', 'each', 'shared', 'variable', 'x', 'and', 'each', 'process', 'p', ':', 'ffl', 'xp', ',', 'a', 'local', 'copy', 'of', 'variable', 'x', 'at', 'process', 'p', '.', 'It', 'is', 'initialized', 'to', 'the', 'initial', 'value', 'of', 'x.', 'ffl', 'Xp', ',', 'a', 'set', 'containing', 'the', 'updates', 'performed', 'by', 'remote', 'processes', 'on', 'variable', 'x.', 'Each', 'tuple', 'in', 'Xp', 'consists', 'of', 'three', 'fields', ':', 'the', 'updated', 'value', ',', 'the', 'timestamp', 'of', 'the', 'updating', 'process', ',', 'and', 'the', 'identity', 'of', 'the', 'updating', 'process', '.', 'It', 'is', 'initialized', 'to', 'an', 'empty', 'set', '.', 'ffl', 'tsp', ',', 'a', 'counter', 'that', 'is', 'used', 'for', 'distinguishing', 'updates', 'by', 'process', 'p', '.', 'It', 'is', 'initialized', 'to', '0', '.', 'Each', 'read', 'and', 'write', 'operation', 'of', 'process', 'p', 'is', 'now', 'translated', 'as', 'follows', '.', '1', '.', 'A', 'read', 'statement', 'v', ':', '=', 'x', 'is', 'translated', 'to', 'v', ':', '=', 'xp', ',', 'i.e.', ',', 'the', 'local', 'copy', 'is', 'read', '.', '2', '.', 'A', 'write', 'statement', 'x', ':', '=', 'm', 'is', 'translated', 'to', 'an', 'update', 'of', 'the', 'local', 'copy', 'along', 'with', 'an', 'increment', 'of', 'the', 'local', 'counter', ',', 'followed', 'by', 'a', 'transmittal', 'of', 'the', 'update', 'to', 'all', 'other', 'processes', ':', 'xp', ';', 'tsp', ':', '=', 'm', ';', 'tsp', '+', '1', ';', 'h8q', ':', 'q', '<', '>', 'p', ':', 'Xq', ':', '=', 'Xq', '-LSB-', 'f', '-LRB-', 'm', ';', 'tsp', ';', 'p', '-RRB-', 'gi', '.', '3', '.', 'Finally', ',', 'for', 'each', 'shared', 'variable', 'x', ',', 'we', 'add', 'a', 'process', 'Mp', ';', 'x', 'that', 'services', 'the', 'remote', 'updates', 'for', 'variable', 'x', 'at', 'process', 'p.', 'Process', 'Mp', ';', 'x', 'examines', 'the', 'contents', 'of', 'set', 'Xp', 'and', 'assigns', 'the', 'values', 'existing', 'there', 'to', 'xp', 'in', 'a', 'FIFO', 'order', ':', 'repeat', 'if', 'Xp', '<', '>', 'fg', 'then', 'xp', ';', 'Xp', ':', '=', 'm', ';', 'Xp', '?', 'f', '-LRB-', 'm', ';', 'ts', ';', 'q', '-RRB-', 'g', 'where', 'Min', '-LRB-', 'Xp', ';', '-LRB-', 'm', ';', 'ts', ';', 'q', '-RRB-', '-RRB-', 'forever', 'Predicate', 'Min', '-LRB-', 'S', ';', 't', '-RRB-', 'denotes', 'that', 'tuple', 't', 'is', 'a', 'minimal', 'element', 'in', 'set', 'S', 'in', 'a', 'specified', 'ordering', '.', 'In', 'this', 'case', ',', 'tuple', 't', 'is', 'less', 'than', 'tuple', 't0', 'provided', 'they', 'mention', 'the', 'same']
Document BIO Tags:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']
Extractive/present Keyphrases:  ['concurrency']
Abstractive/absent Keyphrases:  ['memory consistency conditions', 'program correctness']

-----------

Sample from test data split
Fields in the sample:  ['id', 'document', 'doc_bio_tags', 'extractive_keyphrases', 'abstractive_keyphrases', 'other_metadata']
Tokenized Document:  ['Dynamic', 'analysis', 'of', 'some', 'Relational', 'Data', 'Bases', 'parameters', 'I', ':', 'Projections', 'Dani?ele', 'GARDY', '?', 'Guy', 'LOUCHARDy', 'January', '1994', 'Abstract', 'We', 'present', 'a', 'dynamic', 'study', 'of', 'a', 'data', 'structure', 'related', 'to', 'relational', 'databases', '.', 'We', 'show', 'that', 'some', 'parameters', 'of', 'relational', 'databases', '-LRB-', 'sizes', 'of', 'projections', '-RRB-', ',', 'related', 'to', 'an', 'occupancy', 'problem', 'in', 'urn', 'models', ',', 'behave', 'asymptotically', 'as', 'gaussian', 'stochastic', 'processes', 'under', 'a', 'sequence', 'of', 'updates', 'and', 'queries', '.', 'As', 'a', 'consequence', ',', 'we', 'analyze', 'the', 'distribution', 'of', 'the', 'maximum', 'size', 'of', 'the', 'projection', '.', '1', 'Introduction', 'We', 'consider', 'dynamic', 'objects', ',', 'obtained', 'by', 'updating', 'and', 'querying', 'a', 'data', 'structure', ',', 'on', 'which', 'we', 'want', 'to', 'study', 'a', 'parameter', ',', 'most', 'often', 'defining', 'some', 'size', '.', 'This', 'parameter', 'defines', 'a', 'random', 'variable', ',', 'and', 'we', 'study', 'its', 'behaviour', 'when', 'the', 'initial', 'object', 'is', 'submitted', 'to', 'a', 'sequence', 'of', 'insertions', ',', 'deletions', 'and', 'queries', ',', 'characterizing', 'it', '-LRB-', 'when', 'possible', '-RRB-', 'as', 'a', 'gaussian', 'stochastic', 'process', '.', 'The', 'dynamic', 'objects', 'are', 'here', 'relations', 'in', 'a', 'relational', 'database', ',', 'and', 'the', 'parameter', 'we', 'want', 'to', 'study', 'is', 'the', 'size', 'of', 'their', 'projection', 'on', 'a', 'set', 'of', 'attributes', '.', 'We', 'gave', 'in', 'a', 'former', 'paper', 'conditions', 'which', 'ensure', 'that', ',', 'in', 'the', 'static', 'case', '-LRB-', 'i.e.', 'at', 'a', 'given', 'time', '-RRB-', ',', 'the', 'size', 'of', 'the', 'projection', 'of', 'a', 'relation', 'follows', 'a', 'normal', 'limiting', 'distribution', '.', 'Our', 'goal', 'here', 'is', 'to', 'study', 'the', 'variation', 'of', 'the', 'size', 'of', 'the', 'projection', 'under', 'a', 'sequence', 'of', 'queries', 'and', 'updates', '.', 'We', 'shall', 'show', 'that', 'it', 'is', 'a', 'gaussian', 'process', ',', 'and', 'analyze', 'its', 'maximum', '.', '?', 'Laboratoire', 'PRISM', ',', 'Universit?e', 'de', 'Versailles', 'Saint-Quentin', ',', '78035', 'Versailles', '-LRB-', 'France', '-RRB-', '.', 'This', 'research', 'was', 'partly', 'supported', 'by', 'ESPRIT', 'III-Basic', 'Research', 'Action', 'ALCOM', 'II', '-LRB-', 'no.', '7141', '-RRB-', ',', 'by', 'the', 'CNRS', 'PRC', 'Math?ematique', '-', 'Informatique', 'and', 'by', 'a', 'cooperation', 'between', 'the', 'CNRS', 'and', 'the', 'FNRS', '.', 'yD?epartement', "d'Informatique", ',', 'Universit?e', 'Libre', 'de', 'Bruxelles', ',', 'Bruxelles', '-LRB-', 'Belgique', '-RRB-', '.', 'This', 'research', 'was', 'partially', 'supported', 'by', 'a', 'cooperation', 'between', 'the', 'FNRS', 'and', 'the', 'CNRS', '.', 'R', 'X', 'Y', 'x0', 'y0', 'x1', 'y1', 'x1', 'y2', 'ssX', '-LRB-', 'R', '-RRB-', 'X', 'x0', 'x1', 'Figure', '1', ':', 'Projection', 'of', 'the', 'relation', 'R', '-LSB-', 'X', ',', 'Y', '-RSB-', 'on', 'the', 'attribute', 'X', 'The', 'paper', 'is', 'organized', 'as', 'follows', '.', 'Section', '2', 'presents', 'the', 'database', 'parameters', 'that', 'we', 'shall', 'study', 'and', 'gives', 'a', 'modelization', 'in', 'terms', 'of', 'urn', 'models', ',', 'then', 'briefly', 'recalls', 'the', 'sequences', 'of', 'operations', 'which', 'may', 'be', 'considered', '.', 'Section', '3', 'gives', 'our', 'main', 'results', '-LRB-', 'characterization', 'of', 'the', 'parameter', 'we', 'study', 'as', 'a', 'gaussian', 'process', 'and', 'distribution', 'of', 'its', 'maximum', '-RRB-', 'and', 'presents', 'an', 'overview', 'of', 'our', 'method', ',', 'with', 'a', 'sketch', 'of', 'the', 'proof', '.', 'Section', '4', 'introduces', 'our', 'notations', ',', 'then', 'Section', '5', 'presents', 'the', 'basic', 'processes', '-LRB-', 'number', 'of', 'tuples', 'in', 'a', 'relation', '-RRB-', 'corresponding', 'to', 'different', 'update', 'models', 'and', 'to', 'several', 'constraints', 'on', 'the', 'initial', 'objects', '-LRB-', 'relations', '-RRB-', '.', 'Sections', '6', 'to', '10', 'are', 'devoted', 'to', 'the', 'detailed', 'proofs', '.', '2', 'Databases', 'and', 'urn', 'models', '2.1', 'Projections', 'and', 'the', 'occupancy', 'problem', 'in', 'urn', 'models', 'We', 'briefly', 'recall', 'here', 'some', 'definitions', 'relative', 'to', 'relational', 'databases', 'and', 'to', 'the', 'modelization', 'of', 'relations', ';', 'we', 'refer', 'the', 'reader', 'to', '-LSB-', '7', '-RSB-', 'for', 'a', 'detailed', 'presentation', '.', 'The', 'basic', 'objects', 'we', 'consider', 'are', 'relations', ',', 'which', 'are', 'sets', 'of', '-LRB-', 'distinct', '-RRB-', 'tuples', '.', 'They', 'can', 'be', 'seen', 'as', 'tables', ':', 'a', 'row', 'represents', 'a', 'tuple', ',', 'and', 'the', 'number', 'of', 'lines', 'is', 'the', 'number', 'of', 'elements', 'of', 'the', 'relation', '-LRB-', 'its', 'size', '-RRB-', ';', 'the', 'columns', 'are', 'called', 'the', 'attributes', '.', 'The', 'projection', 'of', 'a', 'relation', 'on', 'a', 'subset', 'of', 'the', 'set', 'of', 'attributes', 'is', 'a', 'new', 'relation', ',', 'obtained', 'by', 'suppressing', 'the', 'corresponding', 'columns', ',', 'then', 'all', 'the', 'duplicate', 'rows', 'in', 'the', 'resulting', 'table', ':', 'We', 'keep', 'only', 'one', 'instance', 'of', 'each', 'tuple', '.', 'We', 'give', 'in', 'Figure', '1', 'an', 'instance', 'of', 'a', 'relation', 'R', '-LSB-', 'X', ',', 'Y', '-RSB-', 'and', 'of', 'its', 'projection', '-LRB-', 'noted', 'ssX', '-LRB-', 'R', '-RRB-', '-RRB-', 'on', 'the', 'attribute', 'X.', 'For', 'ease', 'of', 'presentation', ',', 'and', 'without', 'loss', 'of', 'generality', ',', 'we', 'shall', 'restrict', 'ourselves', 'to', 'the', 'case', 'of', 'a', 'relation', 'R', 'with', 'two', 'attributes', 'X', 'and', 'Y', ',', 'and', 'of', 'its', 'projection', 'on', 'X', '.', 'We', 'shall', 'use', 'the', 'terms', 'initial', 'relation', 'for', 'the', 'relation', 'R', ',', 'and', 'derived', 'relation', 'for', 'its', 'projection', '.', 'Let', 'd', 'be', 'the', 'number', 'of', 'distinct', 'possible', 'values', 'for', 'the', 'attribute', 'X', ';', 'we', 'assume', 'that', ',', 'although', 'it', 'may', 'become', 'large', ',', 'd', 'is', 'finite', '.', 'The', 'projection', 'of', 'the', 'relation', 'R', 'can', 'be', 'modelized', 'with', 'urns', 'and', 'balls', ',', 'according', 'to', 'a', 'well-known', 'occupancy', 'model', ',', 'as', 'follows', '.', 'We', 'consider', 'a', 'sequence', 'of', 'd', 'urns', ',', 'each', 'urn', 'being', 'labelled', 'with', 'a', 'distinct', 'value', 'of', 'the', 'attribute', 'X.', 'To', 'each', 'tuple', 'of', 'the', 'relation', 'R', ',', 'we', 'associate', 'a', 'ball', 'labelled', 'by', 'the', 'value', 'of', 'the', 'tuple', 'on', 'the', 'column', 'X', ';', 'this', 'ball', 'falls', 'into', 'the', 'corresponding', 'urn', '.', 'An', 'equivalent', 'way', 'of', 'seeing', 'this', 'phenomenon', 'is', 'to', 'consider', 'instead', 'that', 'we', 'have', 'a', 'finite', 'supply', 'of', 'balls', ',', 'and', 'that', 'we', 'allocate', 'them', 'at', 'random', 'among', 'the', 'd', 'urns', ',', 'each', 'trial', 'being', 'independent', 'of', 'the', 'others', '.', 'Each', 'ball', 'then', 'receives', 'the', 'label', 'of', 'the', 'urn', 'it', 'falls', 'into', '.', 'After', 'coupling', 'all', 'the', 'tuples', 'of', 'the', 'initial', 'relation', 'R', 'with', 'urns', ',', 'some', 'urns', 'are', 'empty', 'and', 'some', 'contain', 'at', 'least', 'one', 'ball', '.', 'The', 'number', 'of', 'urns', 'with', 'at', 'least', 'one', 'ball', 'is', 'exactly', 'the', 'number', 'of', 'tuples', 'in', 'the', 'projection', 'of', 'the', 'relation', 'R.', 'If', ',', 'instead', 'of', 'the', 'number', 'of', 'urns', 'with', 'at', 'least', 'one', 'ball', ',', 'we', 'consider', 'the', 'number', 'of', 'empty', 'urns', ',', 'and', 'if', 'we', 'assume', 'that', 'each', 'urn', 'can', 'receive', 'an', 'unbounded', 'number', 'of', 'balls', ',', 'then', 'we', 'have', 'the', 'classical', 'occupancy', 'problem', 'presented', 'for', 'example', 'in', '-LSB-', '8', '-RSB-', '.', 'Assuming', 'that', 'the', 'urn', 'size', 'is', 'infinite', 'corresponds', ',', 'in', 'terms', 'of', 'relational', 'databases', ',', 'to', 'a']
Document BIO Tags:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']
Extractive/present Keyphrases:  ['derived relation', 'gaussian process', 'occupancy problem', 'relational database', 'urn model']
Abstractive/absent Keyphrases:  []

-----------
```

### Keyphrase Extraction
```python
from datasets import load_dataset

# get the dataset only for keyphrase extraction
dataset = load_dataset("midas/cstr", "extraction")

print("Samples for Keyphrase Extraction")

# sample from the train split
print("Sample from train data split")
test_sample = dataset["train"][0]
print("Fields in the sample: ", [key for key in test_sample.keys()])
print("Tokenized Document: ", test_sample["document"])
print("Document BIO Tags: ", test_sample["doc_bio_tags"])
print("\n-----------\n")

# sample from the test split
print("Sample from test data split")
test_sample = dataset["test"][0]
print("Fields in the sample: ", [key for key in test_sample.keys()])
print("Tokenized Document: ", test_sample["document"])
print("Document BIO Tags: ", test_sample["doc_bio_tags"])
print("\n-----------\n")
```

### Keyphrase Generation
```python
# get the dataset only for keyphrase generation
dataset = load_dataset("midas/cstr", "generation")

print("Samples for Keyphrase Generation")

# sample from the train split
print("Sample from train data split")
test_sample = dataset["train"][0]
print("Fields in the sample: ", [key for key in test_sample.keys()])
print("Tokenized Document: ", test_sample["document"])
print("Extractive/present Keyphrases: ", test_sample["extractive_keyphrases"])
print("Abstractive/absent Keyphrases: ", test_sample["abstractive_keyphrases"])
print("\n-----------\n")

# sample from the test split
print("Sample from test data split")
test_sample = dataset["test"][0]
print("Fields in the sample: ", [key for key in test_sample.keys()])
print("Tokenized Document: ", test_sample["document"])
print("Extractive/present Keyphrases: ", test_sample["extractive_keyphrases"])
print("Abstractive/absent Keyphrases: ", test_sample["abstractive_keyphrases"])
print("\n-----------\n")
```

## Citation Information
```
@inproceedings{10.1145/313238.313437,
author = {Witten, Ian H. and Paynter, Gordon W. and Frank, Eibe and Gutwin, Carl and Nevill-Manning, Craig G.},
title = {KEA: Practical Automatic Keyphrase Extraction},
year = {1999},
isbn = {1581131453},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/313238.313437},
doi = {10.1145/313238.313437},
booktitle = {Proceedings of the Fourth ACM Conference on Digital Libraries},
pages = {254–255},
numpages = {2},
location = {Berkeley, California, USA},
series = {DL '99}
}
```

## Contributions
Thanks to [@debanjanbhucs](https://github.com/debanjanbhucs), [@dibyaaaaax](https://github.com/dibyaaaaax) and [@ad6398](https://github.com/ad6398) for adding this dataset
